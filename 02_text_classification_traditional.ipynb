{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfe8e5b4",
   "metadata": {},
   "source": [
    "# Exercise 2: Traditional Text Classification\n",
    "\n",
    "Welcome to text classification! You'll learn how to automatically categorize text using traditional machine learning methods.\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this exercise, you will be able to:\n",
    "1. **Feature Engineering**: Convert text to numerical features (TF-IDF, Count Vectors)\n",
    "2. **Dataset Creation**: Build and prepare text classification datasets\n",
    "3. **Model Training**: Train traditional ML classifiers (Naive Bayes, SVM, Logistic Regression)\n",
    "4. **Model Evaluation**: Assess classifier performance using metrics and cross-validation\n",
    "5. **German Text Classification**: Handle German language specifics\n",
    "6. **Pipeline Creation**: Build complete classification pipelines\n",
    "\n",
    "## What You'll Build\n",
    "- German sentiment analysis system\n",
    "- Multi-class text classifier\n",
    "- Feature comparison tools\n",
    "- Model evaluation framework\n",
    "- Production-ready classification pipeline\n",
    "\n",
    "## Applications\n",
    "- **Sentiment Analysis**: Classify reviews as positive/negative\n",
    "- **Topic Classification**: Categorize news articles by topic\n",
    "- **Spam Detection**: Filter unwanted emails\n",
    "- **Content Moderation**: Identify inappropriate content\n",
    "\n",
    "**Ready to build your first text classifier?** ðŸ¤–"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58db76f",
   "metadata": {},
   "source": [
    "## Exercise 1: Building Your First Text Classifier\n",
    "\n",
    "**Goal**: Create a German sentiment analysis system using traditional machine learning.\n",
    "\n",
    "**Your Tasks**: \n",
    "1. Prepare text data and labels\n",
    "2. Create feature vectors from text\n",
    "3. Train multiple classifiers\n",
    "4. Evaluate and compare performance\n",
    "\n",
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a512088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports for text classification\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Scikit-learn for machine learning\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Text preprocessing\n",
    "import re\n",
    "import string\n",
    "\n",
    "print(\"ðŸ¤– Text Classification Toolkit Ready!\")\n",
    "print(\"Available classifiers: Naive Bayes, Logistic Regression, SVM, Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9058f6cb",
   "metadata": {},
   "source": [
    "### Step 1: Create Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd952c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample German sentiment dataset\n",
    "# In practice, you would load this from a file or API\n",
    "\n",
    "# Create a tiny, simple dataset\n",
    "texts = [\n",
    "    \"Das ist super gut\",      # positive\n",
    "    \"Ich bin sehr glÃ¼cklich\", # positive  \n",
    "    \"Fantastisch\",           # positive\n",
    "    \"Das ist schlecht\",      # negative\n",
    "    \"Ich bin traurig\",       # negative\n",
    "    \"Furchtbar\"              # negative\n",
    "]\n",
    "\n",
    "labels = [\"positive\", \"positive\", \"positive\", \"negative\", \"negative\", \"negative\"]\n",
    "\n",
    "print(\"Our simple dataset:\")\n",
    "for text, label in zip(texts, labels):\n",
    "    print(f\"'{text}' -> {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a9bf09",
   "metadata": {},
   "source": [
    "### Step 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a542d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text, remove_stopwords=True, min_length=2):\n",
    "    \"\"\"\n",
    "    Preprocess German text for classification.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Input text\n",
    "        remove_stopwords (bool): Whether to remove stopwords\n",
    "        min_length (int): Minimum word length to keep\n",
    "    \n",
    "    Returns:\n",
    "        str: Preprocessed text\n",
    "    \"\"\"\n",
    "    # TODO: Implement text preprocessing:\n",
    "    # 1. Convert to lowercase\n",
    "    # 2. Remove special characters and digits\n",
    "    # 3. Remove extra whitespace\n",
    "    # 4. Optionally remove stopwords\n",
    "    # 5. Filter words by minimum length\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and digits, keep only letters and spaces\n",
    "    text = re.sub(r'[^a-zÃ¤Ã¶Ã¼ÃŸ\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove stopwords and filter by length\n",
    "    if remove_stopwords:\n",
    "        words = text.split()\n",
    "        words = [word for word in words if word not in german_stopwords and len(word) >= min_length]\n",
    "        text = ' '.join(words)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['text_processed'] = df['text'].apply(preprocess_text)\n",
    "\n",
    "print(\"Preprocessing example:\")\n",
    "for i in range(3):\n",
    "    print(f\"Original: {df['text'].iloc[i]}\")\n",
    "    print(f\"Processed: {df['text_processed'].iloc[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f75e5",
   "metadata": {},
   "source": [
    "### Step 3: Feature Extraction Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba6d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_feature_extraction_methods(texts, labels):\n",
    "    \"\"\"\n",
    "    Compare different feature extraction methods.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of preprocessed texts\n",
    "        labels (list): List of labels\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results for different feature extraction methods\n",
    "    \"\"\"\n",
    "    # TODO: Implement and compare the following feature extraction methods:\n",
    "    # 1. Count Vectorizer (Bag of Words)\n",
    "    # 2. TF-IDF Vectorizer (word level)\n",
    "    # 3. TF-IDF Vectorizer with n-grams\n",
    "    \n",
    "    methods = {}\n",
    "    \n",
    "    # Split data for testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=0.3, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Method 1: Count Vectorizer (Bag of Words)\n",
    "    count_vectorizer = CountVectorizer(max_features=1000)\n",
    "    X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "    X_test_count = count_vectorizer.transform(X_test)\n",
    "    \n",
    "    # Train a simple Naive Bayes classifier\n",
    "    nb_count = MultinomialNB()\n",
    "    nb_count.fit(X_train_count, y_train)\n",
    "    count_accuracy = nb_count.score(X_test_count, y_test)\n",
    "    \n",
    "    methods['Count Vectorizer'] = {\n",
    "        'vectorizer': count_vectorizer,\n",
    "        'accuracy': count_accuracy,\n",
    "        'feature_count': X_train_count.shape[1]\n",
    "    }\n",
    "    \n",
    "    # Method 2: TF-IDF (word level)\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    nb_tfidf = MultinomialNB()\n",
    "    nb_tfidf.fit(X_train_tfidf, y_train)\n",
    "    tfidf_accuracy = nb_tfidf.score(X_test_tfidf, y_test)\n",
    "    \n",
    "    methods['TF-IDF Words'] = {\n",
    "        'vectorizer': tfidf_vectorizer,\n",
    "        'accuracy': tfidf_accuracy,\n",
    "        'feature_count': X_train_tfidf.shape[1]\n",
    "    }\n",
    "    \n",
    "    # Method 3: TF-IDF with n-grams\n",
    "    tfidf_ngram = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))\n",
    "    X_train_ngram = tfidf_ngram.fit_transform(X_train)\n",
    "    X_test_ngram = tfidf_ngram.transform(X_test)\n",
    "    \n",
    "    nb_ngram = MultinomialNB()\n",
    "    nb_ngram.fit(X_train_ngram, y_train)\n",
    "    ngram_accuracy = nb_ngram.score(X_test_ngram, y_test)\n",
    "    \n",
    "    methods['TF-IDF N-grams'] = {\n",
    "        'vectorizer': tfidf_ngram,\n",
    "        'accuracy': ngram_accuracy,\n",
    "        'feature_count': X_train_ngram.shape[1]\n",
    "    }\n",
    "    \n",
    "    return methods, (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Compare feature extraction methods\n",
    "feature_methods, data_split = compare_feature_extraction_methods(\n",
    "    df['text_processed'].tolist(), \n",
    "    df['sentiment'].tolist()\n",
    ")\n",
    "\n",
    "print(\"Feature Extraction Method Comparison:\")\n",
    "for method_name, results in feature_methods.items():\n",
    "    print(f\"{method_name}:\")\n",
    "    print(f\"  Accuracy: {results['accuracy']:.3f}\")\n",
    "    print(f\"  Feature Count: {results['feature_count']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c07ed99",
   "metadata": {},
   "source": [
    "### Step 4: Multi-Algorithm Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04938b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_classification_algorithms(X_train, X_test, y_train, y_test, vectorizer):\n",
    "    \"\"\"\n",
    "    Compare different classification algorithms.\n",
    "    \n",
    "    Args:\n",
    "        X_train, X_test: Training and test texts\n",
    "        y_train, y_test: Training and test labels\n",
    "        vectorizer: Fitted vectorizer to use\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results for different algorithms\n",
    "    \"\"\"\n",
    "    # TODO: Implement and compare the following algorithms:\n",
    "    # 1. Naive Bayes\n",
    "    # 2. Support Vector Machine\n",
    "    # 3. Logistic Regression\n",
    "    # 4. Random Forest\n",
    "    \n",
    "    # Transform texts to features\n",
    "    X_train_vec = vectorizer.transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    algorithms = {\n",
    "        'Naive Bayes': MultinomialNB(),\n",
    "        'SVM': SVC(kernel='linear', random_state=42),\n",
    "        'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, algorithm in algorithms.items():\n",
    "        # Train the algorithm\n",
    "        algorithm.fit(X_train_vec, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = algorithm.predict(X_test_vec)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation score\n",
    "        cv_scores = cross_val_score(algorithm, X_train_vec, y_train, cv=5)\n",
    "        \n",
    "        results[name] = {\n",
    "            'model': algorithm,\n",
    "            'accuracy': accuracy,\n",
    "            'cv_mean': cv_scores.mean(),\n",
    "            'cv_std': cv_scores.std(),\n",
    "            'predictions': y_pred,\n",
    "            'classification_report': classification_report(y_test, y_pred)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Use the best feature extraction method (TF-IDF with n-grams)\n",
    "best_vectorizer = feature_methods['TF-IDF N-grams']['vectorizer']\n",
    "X_train, X_test, y_train, y_test = data_split\n",
    "\n",
    "# Compare algorithms\n",
    "algorithm_results = compare_classification_algorithms(\n",
    "    X_train, X_test, y_train, y_test, best_vectorizer\n",
    ")\n",
    "\n",
    "print(\"Classification Algorithm Comparison:\")\n",
    "for name, results in algorithm_results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Test Accuracy: {results['accuracy']:.3f}\")\n",
    "    print(f\"  CV Score: {results['cv_mean']:.3f} (Â±{results['cv_std']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa65e2",
   "metadata": {},
   "source": [
    "### Step 5: Detailed Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detailed_evaluation(results_dict, y_test, algorithm_name='Logistic Regression'):\n",
    "    \"\"\"\n",
    "    Perform detailed evaluation of the best performing algorithm.\n",
    "    \n",
    "    Args:\n",
    "        results_dict (dict): Algorithm results dictionary\n",
    "        y_test (list): True test labels\n",
    "        algorithm_name (str): Name of algorithm to evaluate\n",
    "    \"\"\"\n",
    "    # TODO: Create detailed evaluation including:\n",
    "    # 1. Confusion matrix visualization\n",
    "    # 2. Classification report\n",
    "    # 3. Feature importance (if available)\n",
    "    \n",
    "    if algorithm_name not in results_dict:\n",
    "        print(f\"Algorithm {algorithm_name} not found in results\")\n",
    "        return\n",
    "    \n",
    "    results = results_dict[algorithm_name]\n",
    "    y_pred = results['predictions']\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=sorted(set(y_test)), \n",
    "                yticklabels=sorted(set(y_test)),\n",
    "                ax=axes[0])\n",
    "    axes[0].set_title(f'Confusion Matrix - {algorithm_name}')\n",
    "    axes[0].set_xlabel('Predicted Label')\n",
    "    axes[0].set_ylabel('True Label')\n",
    "    \n",
    "    # Algorithm Comparison Bar Plot\n",
    "    alg_names = list(results_dict.keys())\n",
    "    accuracies = [results_dict[name]['accuracy'] for name in alg_names]\n",
    "    \n",
    "    axes[1].bar(alg_names, accuracies, color=['skyblue', 'lightcoral', 'lightgreen', 'orange'])\n",
    "    axes[1].set_title('Algorithm Accuracy Comparison')\n",
    "    axes[1].set_ylabel('Accuracy')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    axes[1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(accuracies):\n",
    "        axes[1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed classification report\n",
    "    print(f\"\\nDetailed Classification Report for {algorithm_name}:\")\n",
    "    print(results['classification_report'])\n",
    "\n",
    "# Evaluate the best performing algorithm\n",
    "detailed_evaluation(algorithm_results, y_test, 'Logistic Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16e4304",
   "metadata": {},
   "source": [
    "### Step 6: Pipeline Creation and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7448bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimized_pipeline(texts, labels):\n",
    "    \"\"\"\n",
    "    Create an optimized classification pipeline with hyperparameter tuning.\n",
    "    \n",
    "    Args:\n",
    "        texts (list): List of texts\n",
    "        labels (list): List of labels\n",
    "    \n",
    "    Returns:\n",
    "        Pipeline: Optimized pipeline\n",
    "    \"\"\"\n",
    "    # TODO: Create a pipeline with:\n",
    "    # 1. TF-IDF Vectorization\n",
    "    # 2. Classification algorithm\n",
    "    # 3. Hyperparameter tuning using GridSearchCV\n",
    "    \n",
    "    # Create pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression(random_state=42))\n",
    "    ])\n",
    "    \n",
    "    # Define parameter grid for tuning\n",
    "    param_grid = {\n",
    "        'tfidf__max_features': [500, 1000, 2000],\n",
    "        'tfidf__ngram_range': [(1, 1), (1, 2)],\n",
    "        'tfidf__min_df': [1, 2],\n",
    "        'classifier__C': [0.1, 1, 10]\n",
    "    }\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1\n",
    "    )\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        texts, labels, test_size=0.3, random_state=42, stratify=labels\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get best pipeline\n",
    "    best_pipeline = grid_search.best_estimator_\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_accuracy = best_pipeline.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation score: {grid_search.best_score_:.3f}\")\n",
    "    print(f\"Test accuracy: {test_accuracy:.3f}\")\n",
    "    \n",
    "    return best_pipeline, (X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Create optimized pipeline\n",
    "print(\"Creating optimized pipeline (this may take a moment)...\")\n",
    "best_pipeline, final_data_split = create_optimized_pipeline(\n",
    "    df['text_processed'].tolist(), \n",
    "    df['sentiment'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed36f2",
   "metadata": {},
   "source": [
    "### Step 7: Model Testing and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_predictions(pipeline, test_texts=None):\n",
    "    \"\"\"\n",
    "    Test the trained model with new text examples.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: Trained classification pipeline\n",
    "        test_texts (list): Optional list of test texts\n",
    "    \n",
    "    Returns:\n",
    "        list: Predictions for test texts\n",
    "    \"\"\"\n",
    "    # TODO: Test the model with new examples and get predictions with confidence\n",
    "    \n",
    "    if test_texts is None:\n",
    "        test_texts = [\n",
    "            \"Das Produkt ist absolut fantastisch und sehr empfehlenswert!\",\n",
    "            \"Ich bin sehr enttÃ¤uscht von der schlechten QualitÃ¤t.\",\n",
    "            \"Das ist ein ganz normales Produkt, nichts Besonderes.\",\n",
    "            \"Hervorragende Leistung und ausgezeichneter Service!\",\n",
    "            \"Furchtbar schlecht, das Geld nicht wert.\"\n",
    "        ]\n",
    "    \n",
    "    # Preprocess test texts\n",
    "    processed_texts = [preprocess_text(text) for text in test_texts]\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = pipeline.predict(processed_texts)\n",
    "    \n",
    "    # Get prediction probabilities\n",
    "    try:\n",
    "        probabilities = pipeline.predict_proba(processed_texts)\n",
    "        classes = pipeline.classes_\n",
    "    except:\n",
    "        probabilities = None\n",
    "        classes = None\n",
    "    \n",
    "    print(\"Model Predictions on New Texts:\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for i, (original, processed, pred) in enumerate(zip(test_texts, processed_texts, predictions)):\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Original: {original}\")\n",
    "        print(f\"Processed: {processed}\")\n",
    "        print(f\"Prediction: {pred}\")\n",
    "        \n",
    "        if probabilities is not None:\n",
    "            print(\"Confidence scores:\")\n",
    "            for class_name, prob in zip(classes, probabilities[i]):\n",
    "                print(f\"  {class_name}: {prob:.3f}\")\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# Test the model\n",
    "predictions = test_model_predictions(best_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73316b4",
   "metadata": {},
   "source": [
    "### Step 8: Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f0b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_important_features(pipeline, top_n=10):\n",
    "    \"\"\"\n",
    "    Analyze the most important features for each class.\n",
    "    \n",
    "    Args:\n",
    "        pipeline: Trained pipeline\n",
    "        top_n (int): Number of top features to show per class\n",
    "    \"\"\"\n",
    "    # TODO: Extract and analyze the most important features:\n",
    "    # 1. Get feature names from vectorizer\n",
    "    # 2. Get feature coefficients from classifier\n",
    "    # 3. Find top features for each class\n",
    "    \n",
    "    try:\n",
    "        # Get vectorizer and classifier from pipeline\n",
    "        vectorizer = pipeline.named_steps['tfidf']\n",
    "        classifier = pipeline.named_steps['classifier']\n",
    "        \n",
    "        # Get feature names\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        \n",
    "        # Get coefficients (works for LogisticRegression)\n",
    "        if hasattr(classifier, 'coef_'):\n",
    "            coefficients = classifier.coef_\n",
    "            classes = classifier.classes_\n",
    "            \n",
    "            print(\"Most Important Features by Class:\")\n",
    "            print(\"=\" * 50)\n",
    "            \n",
    "            for i, class_name in enumerate(classes):\n",
    "                print(f\"\\n{class_name.upper()} class:\")\n",
    "                \n",
    "                if len(classes) == 2:  # Binary classification\n",
    "                    # For binary classification, use the single coefficient vector\n",
    "                    coef = coefficients[0] if i == 1 else -coefficients[0]\n",
    "                else:  # Multi-class classification\n",
    "                    coef = coefficients[i]\n",
    "                \n",
    "                # Get top positive coefficients (most indicative)\n",
    "                top_indices = np.argsort(coef)[-top_n:]\n",
    "                top_features = [(feature_names[idx], coef[idx]) for idx in reversed(top_indices)]\n",
    "                \n",
    "                print(\"Most indicative features:\")\n",
    "                for feature, score in top_features:\n",
    "                    print(f\"  {feature}: {score:.3f}\")\n",
    "        else:\n",
    "            print(\"Feature importance analysis not available for this classifier type.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in feature analysis: {e}\")\n",
    "\n",
    "# Analyze important features\n",
    "analyze_important_features(best_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32eec6",
   "metadata": {},
   "source": [
    "## Exercise Tasks\n",
    "\n",
    "Complete the following tasks to deepen your understanding:\n",
    "\n",
    "1. **Dataset Expansion**: \n",
    "   - Create a larger, more diverse German sentiment dataset\n",
    "   - Include different domains (movies, products, restaurants)\n",
    "   - Handle class imbalance using techniques like SMOTE\n",
    "\n",
    "2. **Advanced Feature Engineering**:\n",
    "   - Implement character-level n-grams\n",
    "   - Add sentiment lexicon features\n",
    "   - Include text length and other statistical features\n",
    "\n",
    "3. **Cross-validation Strategy**:\n",
    "   - Implement stratified k-fold cross-validation\n",
    "   - Compare different validation strategies\n",
    "   - Analyze variance in model performance\n",
    "\n",
    "4. **Error Analysis**:\n",
    "   - Identify misclassified examples\n",
    "   - Analyze common error patterns\n",
    "   - Suggest improvements based on errors\n",
    "\n",
    "5. **Model Deployment**:\n",
    "   - Save and load the trained model\n",
    "   - Create a simple web interface for predictions\n",
    "   - Implement batch prediction functionality\n",
    "\n",
    "## Reflection Questions\n",
    "\n",
    "1. Which feature extraction method worked best and why?\n",
    "2. How does the choice of preprocessing affect model performance?\n",
    "3. What are the trade-offs between different classification algorithms?\n",
    "4. How would you handle a much larger dataset?\n",
    "5. What challenges are specific to German text classification?\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Explore ensemble methods (voting, bagging, boosting)\n",
    "- Learn about advanced feature selection techniques\n",
    "- Study domain adaptation for different text types\n",
    "- Prepare for deep learning approaches (next topic!)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
