{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12118646",
   "metadata": {},
   "source": [
    "# Topic 6: Topic Modeling Exercises\n",
    "\n",
    "Welcome to the Topic Modeling workshop! In this notebook, you'll learn how to:\n",
    "- Discover topics in text collections using different algorithms\n",
    "- Understand and implement Latent Dirichlet Allocation (LDA)\n",
    "- Analyze document-topic relationships\n",
    "- Compare different topic models\n",
    "- Explore how topics evolve over time\n",
    "\n",
    "**Before you start:**\n",
    "- Make sure you have installed the required libraries: `pip install scikit-learn gensim matplotlib`\n",
    "- If you encounter numpy/gensim compatibility errors, try: `pip install gensim==4.1.2`\n",
    "- The notebook includes fallback implementations using scikit-learn when gensim is not available\n",
    "\n",
    "**Learning Objectives:**\n",
    "By the end of this notebook, you will be able to:\n",
    "1. Preprocess text data for topic modeling\n",
    "2. Implement simple topic discovery using TF-IDF\n",
    "3. Build advanced LDA models with both Gensim and scikit-learn\n",
    "4. Analyze and visualize document-topic relationships\n",
    "5. Compare models with different numbers of topics\n",
    "6. Explore topic evolution over time\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a945674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports and setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import advanced libraries with helpful error messages\n",
    "try:\n",
    "    from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "    from sklearn.decomposition import LatentDirichletAllocation\n",
    "    SKLEARN_AVAILABLE = True\n",
    "    print(\"‚úÖ scikit-learn available for topic modeling!\")\n",
    "except ImportError:\n",
    "    print(\"‚ùå scikit-learn not available. Please install: pip install scikit-learn\")\n",
    "    SKLEARN_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    import gensim\n",
    "    from gensim import corpora, models\n",
    "    from gensim.models import LdaModel\n",
    "    GENSIM_AVAILABLE = True\n",
    "    print(\"‚úÖ Gensim available for advanced topic modeling!\")\n",
    "except (ImportError, ValueError) as e:\n",
    "    if \"numpy.dtype size changed\" in str(e):\n",
    "        print(\"‚ö†Ô∏è Gensim/NumPy compatibility issue detected.\")\n",
    "        print(\"Solution: pip install --upgrade numpy gensim\")\n",
    "        print(\"Or: pip install gensim==4.1.2 (compatible version)\")\n",
    "    else:\n",
    "        print(\"‚ùå Gensim not available. Please install: pip install gensim\")\n",
    "    GENSIM_AVAILABLE = False\n",
    "\n",
    "print(\"\\nüìö Ready to explore topic modeling!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce1cf89",
   "metadata": {},
   "source": [
    "## Exercise 1: Simple Topic Discovery with TF-IDF\n",
    "\n",
    "**Goal:** Learn the basics of topic modeling by implementing a simple approach using TF-IDF and scikit-learn's LDA.\n",
    "\n",
    "**Your Task:** \n",
    "1. Create a function called `simple_topic_discovery()` that takes documents and discovers topics\n",
    "2. Use TF-IDF to convert text to numerical features\n",
    "3. Apply LDA to find topics\n",
    "4. Extract and display the top words for each topic\n",
    "\n",
    "**Hints:**\n",
    "- Use `TfidfVectorizer` from scikit-learn to create feature vectors\n",
    "- Set `max_features=100` to limit vocabulary size for faster processing\n",
    "- Use `stop_words='english'` to remove common words (or create your own German stop words)\n",
    "- Use `LatentDirichletAllocation` with `n_components` parameter for number of topics\n",
    "- The `components_` attribute of the fitted LDA model contains topic-word distributions\n",
    "- Use `argsort()` to find the indices of words with highest weights in each topic\n",
    "\n",
    "**Sample German Documents (use these for testing):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa0454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample German documents for topic modeling\n",
    "german_documents = [\n",
    "    \"Fu√üball ist sehr beliebt in Deutschland. Viele Menschen spielen gerne Fu√üball.\",\n",
    "    \"Die deutsche Fu√üball-Nationalmannschaft hat schon oft gewonnen.\",\n",
    "    \"Basketball und Tennis sind auch beliebte Sportarten.\",\n",
    "    \"In der K√ºche kocht man viele leckere Gerichte. Deutsche K√ºche ist sehr vielf√§ltig.\",\n",
    "    \"Schnitzel, Bratwurst und Sauerkraut sind typisch deutsche Speisen.\",\n",
    "    \"Viele Menschen kochen gerne zu Hause und probieren neue Rezepte aus.\",\n",
    "    \"Computer und Smartphones sind heute sehr wichtig f√ºr die Arbeit.\",\n",
    "    \"K√ºnstliche Intelligenz und maschinelles Lernen entwickeln sich schnell.\",\n",
    "    \"Viele Unternehmen investieren in neue Technologien und Digitalisierung.\",\n",
    "    \"Das Auto ist ein wichtiges Verkehrsmittel in Deutschland.\",\n",
    "    \"Elektroautos werden immer beliebter und umweltfreundlicher.\",\n",
    "    \"√ñffentliche Verkehrsmittel wie Bus und Bahn sind auch sehr wichtig.\"\n",
    "]\n",
    "\n",
    "print(\"üìÑ Sample Documents Available:\")\n",
    "print(f\"   Number of documents: {len(german_documents)}\")\n",
    "print(f\"   Example: {german_documents[0][:50]}...\")\n",
    "\n",
    "# TODO: Implement your simple_topic_discovery function here\n",
    "def simple_topic_discovery(documents, n_topics=3, n_words=5):\n",
    "    \"\"\"\n",
    "    Discover topics using simple TF-IDF clustering.\n",
    "    \n",
    "    Parameters:\n",
    "    - documents: list of text documents\n",
    "    - n_topics: number of topics to discover\n",
    "    - n_words: number of top words to show per topic\n",
    "    \n",
    "    Returns:\n",
    "    - topics: list of dictionaries with topic information\n",
    "    - doc_topic_dist: document-topic distribution matrix\n",
    "    \n",
    "    Hints:\n",
    "    1. Check if SKLEARN_AVAILABLE is True\n",
    "    2. Create TfidfVectorizer with appropriate parameters\n",
    "    3. Fit and transform documents to get TF-IDF matrix\n",
    "    4. Create and fit LatentDirichletAllocation model\n",
    "    5. Extract topics by finding top words in each topic\n",
    "    6. Return topic information and document-topic distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here - follow the hints above!\n",
    "    pass\n",
    "\n",
    "# Test your function (uncomment after implementing)\n",
    "# topics, doc_distributions = simple_topic_discovery(german_documents, n_topics=4, n_words=6)\n",
    "# print(\"Discovered topics:\", topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a71f61",
   "metadata": {},
   "source": [
    "## Exercise 2: Advanced LDA with Gensim\n",
    "\n",
    "**Goal:** Learn to use Gensim for more sophisticated topic modeling with proper text preprocessing.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create a text preprocessing function for German text\n",
    "2. Implement a wrapper class to make sklearn models compatible with Gensim interface\n",
    "3. Build an advanced LDA modeling function that works with both Gensim and sklearn\n",
    "4. Create a function to display topics in a readable format\n",
    "\n",
    "**Part 2a: Text Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7415415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def preprocess_for_lda(documents):\n",
    "    \"\"\"\n",
    "    Preprocess documents for LDA topic modeling.\n",
    "    \n",
    "    Your task: Implement comprehensive German text preprocessing\n",
    "    \n",
    "    Steps to implement:\n",
    "    1. Create a set of German stop words\n",
    "    2. For each document:\n",
    "       - Convert to lowercase\n",
    "       - Remove punctuation (keep only German letters: a-z√º√§√∂√ü)\n",
    "       - Split into words\n",
    "       - Remove stop words and short words (< 3 characters)\n",
    "    3. Return list of preprocessed documents (each as list of words)\n",
    "    \n",
    "    Hints:\n",
    "    - Use re.sub() with pattern r'[^a-z√º√§√∂√ü\\s]' to keep only German letters\n",
    "    - German stop words: 'der', 'die', 'das', 'und', 'ist', 'sind', 'ein', 'eine', 'in', 'zu', etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Define German stop words\n",
    "    german_stops = {\n",
    "        # Add German stop words here\n",
    "        # Hint: include words like 'der', 'die', 'das', 'und', 'ist', 'sind'...\n",
    "    }\n",
    "    \n",
    "    processed_docs = []\n",
    "    \n",
    "    # TODO: Implement preprocessing loop\n",
    "    # for doc in documents:\n",
    "    #     # Convert to lowercase and remove punctuation\n",
    "    #     # Split into words\n",
    "    #     # Remove stop words and short words\n",
    "    #     # Append to processed_docs\n",
    "    \n",
    "    return processed_docs\n",
    "\n",
    "# Test your preprocessing function\n",
    "# processed_example = preprocess_for_lda(german_documents[:2])\n",
    "# print(\"Processed example:\", processed_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd96afc",
   "metadata": {},
   "source": [
    "**Part 2b: Sklearn-Gensim Compatibility Wrapper**\n",
    "\n",
    "Create a wrapper class to make sklearn LDA models work with Gensim-style interfaces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9041f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SklearnLDAWrapper:\n",
    "    \"\"\"\n",
    "    Wrapper to make sklearn LDA models compatible with gensim interface.\n",
    "    \n",
    "    Your task: Implement the missing methods\n",
    "    \n",
    "    The wrapper should:\n",
    "    1. Store the sklearn model, feature names, and number of topics\n",
    "    2. Provide a print_topics() method that returns topics in Gensim format\n",
    "    3. Provide a log_perplexity() method for model evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sklearn_model, feature_names, n_topics):\n",
    "        # TODO: Store the parameters\n",
    "        pass\n",
    "    \n",
    "    def print_topics(self, num_words=8):\n",
    "        \"\"\"\n",
    "        Return topics in Gensim-compatible format.\n",
    "        \n",
    "        Hints:\n",
    "        - Use sklearn_model.components_ to get topic-word distributions\n",
    "        - For each topic, find top words using argsort()\n",
    "        - Format as: [(topic_idx, 'word1*prob1 + word2*prob2 + ...'), ...]\n",
    "        \"\"\"\n",
    "        topics = []\n",
    "        # TODO: Implement topic extraction\n",
    "        # for topic_idx, topic in enumerate(self.sklearn_model.components_):\n",
    "        #     # Find top words and their probabilities\n",
    "        #     # Format as required\n",
    "        return topics\n",
    "    \n",
    "    def log_perplexity(self, corpus):\n",
    "        \"\"\"Calculate perplexity (approximate for sklearn models).\"\"\"\n",
    "        try:\n",
    "            return self.sklearn_model.perplexity(corpus)\n",
    "        except:\n",
    "            return float('inf')\n",
    "\n",
    "# Test your wrapper (after implementing the methods above)\n",
    "# wrapper_test = SklearnLDAWrapper(None, ['test', 'words'], 2)\n",
    "# print(\"Wrapper created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef4cd13",
   "metadata": {},
   "source": [
    "**Part 2c: Advanced LDA Modeling Function**\n",
    "\n",
    "Create a function that can use either Gensim or sklearn for LDA modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_lda_modeling(documents, n_topics=4, passes=10):\n",
    "    \"\"\"\n",
    "    Perform advanced LDA topic modeling with Gensim or sklearn fallback.\n",
    "    \n",
    "    Your task: Implement both Gensim and sklearn approaches\n",
    "    \n",
    "    Steps:\n",
    "    1. Check if GENSIM_AVAILABLE, if not, use sklearn fallback\n",
    "    2. For Gensim approach:\n",
    "       - Preprocess documents using your preprocess_for_lda function\n",
    "       - Create Dictionary and filter extremes\n",
    "       - Create bag-of-words corpus\n",
    "       - Train LdaModel with specified parameters\n",
    "    3. For sklearn fallback:\n",
    "       - Use your SklearnLDAWrapper and TfidfVectorizer\n",
    "    4. Return model, corpus, and dictionary (or equivalent)\n",
    "    \n",
    "    Parameters:\n",
    "    - documents: list of text documents\n",
    "    - n_topics: number of topics to discover\n",
    "    - passes: number of training passes (for Gensim)\n",
    "    \n",
    "    Returns:\n",
    "    - lda_model: trained LDA model (Gensim or wrapped sklearn)\n",
    "    - corpus: corpus in appropriate format\n",
    "    - dictionary: word dictionary (Gensim) or vectorizer (sklearn)\n",
    "    \"\"\"\n",
    "    \n",
    "    if not GENSIM_AVAILABLE:\n",
    "        print(\"Gensim not available. Using scikit-learn LDA as fallback.\")\n",
    "        # TODO: Implement sklearn fallback\n",
    "        # Use preprocess_for_lda, TfidfVectorizer, LatentDirichletAllocation\n",
    "        # Return wrapped model\n",
    "        return None, None, None\n",
    "    \n",
    "    print(\"Using Gensim for advanced LDA modeling...\")\n",
    "    \n",
    "    # TODO: Implement Gensim approach\n",
    "    # 1. Preprocess documents\n",
    "    # 2. Create dictionary and filter extremes\n",
    "    # 3. Create corpus\n",
    "    # 4. Train LDA model\n",
    "    # 5. Return results\n",
    "    \n",
    "    return None, None, None\n",
    "\n",
    "# Extended document collection for better topic modeling\n",
    "extended_documents = german_documents + [\n",
    "    \"Reisen macht Spa√ü und man lernt neue Kulturen kennen.\",\n",
    "    \"Urlaub am Meer oder in den Bergen ist sehr entspannend.\",\n",
    "    \"Viele Menschen reisen gerne in andere L√§nder und St√§dte.\",\n",
    "    \"B√ºcher lesen ist ein sch√∂nes Hobby und sehr entspannend.\",\n",
    "    \"In der Bibliothek findet man viele interessante B√ºcher.\",\n",
    "    \"Musik h√∂ren und Konzerte besuchen macht vielen Menschen Freude.\",\n",
    "    \"Garten und Pflanzen pflegen ist ein beliebtes Hobby.\",\n",
    "    \"Blumen und Gem√ºse wachsen gut im eigenen Garten.\",\n",
    "    \"Natur und Umwelt sind wichtig f√ºr unser Leben.\"\n",
    "]\n",
    "\n",
    "print(\"üìö Extended Document Collection Ready!\")\n",
    "print(f\"   Total documents: {len(extended_documents)}\")\n",
    "\n",
    "# Test your advanced modeling function (uncomment after implementing)\n",
    "# lda_model, corpus, dictionary = advanced_lda_modeling(extended_documents, n_topics=5)\n",
    "# print(\"Advanced LDA model trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb5b623",
   "metadata": {},
   "source": [
    "## Exercise 3: Document-Topic Analysis\n",
    "\n",
    "**Goal:** Learn how to analyze the relationship between documents and topics, and create visualizations.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create a function to analyze document-topic relationships\n",
    "2. Build visualizations showing topic distributions\n",
    "3. Calculate topic assignment statistics\n",
    "\n",
    "**Hints for document-topic analysis:**\n",
    "- Use `get_document_topics()` method for Gensim models\n",
    "- Use `transform()` method for sklearn models\n",
    "- Sort topics by probability for each document\n",
    "- Create bar charts and histograms for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d2e44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_document_topics(lda_model, corpus, documents, dictionary):\n",
    "    \"\"\"\n",
    "    Analyze how documents relate to topics.\n",
    "    \n",
    "    Your task: Implement document-topic analysis\n",
    "    \n",
    "    Steps:\n",
    "    1. Check if model is available\n",
    "    2. For each document, get topic distribution\n",
    "    3. Find main topic and probability for each document\n",
    "    4. Display results in readable format\n",
    "    5. Return analysis results for further processing\n",
    "    \n",
    "    Hints:\n",
    "    - Use hasattr(lda_model, 'get_document_topics') to check if it's Gensim\n",
    "    - For sklearn models, you'll need to transform the documents first\n",
    "    - Sort topic distributions by probability (highest first)\n",
    "    - Truncate long document text for display\n",
    "    \"\"\"\n",
    "    \n",
    "    if not lda_model:\n",
    "        print(\"LDA model not available.\")\n",
    "        return\n",
    "    \n",
    "    print(\"Document-Topic Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    doc_topics = []\n",
    "    \n",
    "    # TODO: Implement document-topic analysis\n",
    "    # Check if Gensim or sklearn model\n",
    "    # Process each document and get topic distribution\n",
    "    # Store results in doc_topics list\n",
    "    \n",
    "    return doc_topics\n",
    "\n",
    "def create_topic_visualization(doc_topics, lda_model):\n",
    "    \"\"\"\n",
    "    Create visualizations for topic analysis.\n",
    "    \n",
    "    Your task: Create informative plots\n",
    "    \n",
    "    Create two plots:\n",
    "    1. Bar chart showing number of documents per topic\n",
    "    2. Histogram showing distribution of topic probabilities\n",
    "    \n",
    "    Hints:\n",
    "    - Use Counter to count main topics\n",
    "    - Use plt.subplot(1, 2, 1) and plt.subplot(1, 2, 2) for side-by-side plots\n",
    "    - Add labels, titles, and legends\n",
    "    - Use plt.tight_layout() for better spacing\n",
    "    \"\"\"\n",
    "    \n",
    "    if not doc_topics or not lda_model:\n",
    "        print(\"No data available for visualization.\")\n",
    "        return\n",
    "    \n",
    "    # TODO: Implement visualization\n",
    "    # Extract main topics and probabilities\n",
    "    # Create bar chart and histogram\n",
    "    # Add statistics\n",
    "    \n",
    "    pass\n",
    "\n",
    "# TODO: Test your analysis functions (after implementing advanced_lda_modeling)\n",
    "# if lda_model and corpus:\n",
    "#     doc_topic_analysis = analyze_document_topics(lda_model, corpus, extended_documents, dictionary)\n",
    "#     if doc_topic_analysis:\n",
    "#         create_topic_visualization(doc_topic_analysis, lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d1a764",
   "metadata": {},
   "source": [
    "## Exercise 4: Topic Model Comparison\n",
    "\n",
    "**Goal:** Learn how to compare topic models with different numbers of topics to find the optimal number.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create a function to compare LDA models with different topic counts\n",
    "2. Calculate perplexity and coherence scores\n",
    "3. Visualize the comparison results\n",
    "4. Recommend the best model based on metrics\n",
    "\n",
    "**Key Concepts:**\n",
    "- **Perplexity**: Lower values indicate better fit (but watch for overfitting)\n",
    "- **Coherence**: Higher values indicate more interpretable topics\n",
    "- **Model Selection**: Balance between fit and interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53769614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_topic_models(documents, topic_range=[3, 4, 5, 6]):\n",
    "    \"\"\"\n",
    "    Compare LDA models with different numbers of topics.\n",
    "    \n",
    "    Your task: Implement model comparison\n",
    "    \n",
    "    Steps:\n",
    "    1. Check library availability (Gensim preferred, sklearn fallback)\n",
    "    2. For each number of topics in topic_range:\n",
    "       - Train a model\n",
    "       - Calculate perplexity\n",
    "       - Calculate coherence (if possible)\n",
    "       - Store results\n",
    "    3. Create visualization comparing metrics\n",
    "    4. Recommend best model\n",
    "    \n",
    "    Parameters:\n",
    "    - documents: list of text documents\n",
    "    - topic_range: list of topic numbers to test\n",
    "    \n",
    "    Returns:\n",
    "    - models: list of trained models\n",
    "    - perplexities: list of perplexity scores\n",
    "    - coherences: list of coherence scores\n",
    "    \n",
    "    Hints:\n",
    "    - Use CoherenceModel from gensim.models for coherence calculation\n",
    "    - Create side-by-side plots for perplexity and coherence\n",
    "    - Use different colors for different metrics\n",
    "    - Add value labels on plot points\n",
    "    \"\"\"\n",
    "    \n",
    "    if not GENSIM_AVAILABLE:\n",
    "        print(\"Gensim not available for model comparison.\")\n",
    "        print(\"Using sklearn fallback for basic comparison...\")\n",
    "        # TODO: Implement sklearn-only comparison\n",
    "        return None\n",
    "    \n",
    "    print(\"Comparing Topic Models:\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # TODO: Implement full comparison\n",
    "    # 1. Preprocess documents\n",
    "    # 2. Create dictionary and corpus\n",
    "    # 3. Train models for each topic count\n",
    "    # 4. Calculate metrics\n",
    "    # 5. Create visualizations\n",
    "    # 6. Make recommendations\n",
    "    \n",
    "    models = []\n",
    "    perplexities = []\n",
    "    coherences = []\n",
    "    \n",
    "    return models, perplexities, coherences\n",
    "\n",
    "# TODO: Test your comparison function\n",
    "# comparison_results = compare_topic_models(extended_documents, topic_range=[3, 4, 5, 6])\n",
    "# print(\"Model comparison completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993ec797",
   "metadata": {},
   "source": [
    "## Exercise 5: Topic Evolution and Trends\n",
    "\n",
    "**Goal:** Explore how topics might change over time by analyzing different document collections.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Create simulated time periods with different document themes\n",
    "2. Train separate models for each time period\n",
    "3. Analyze how topic words change across periods\n",
    "4. Visualize topic trends over time\n",
    "\n",
    "**Real-world Applications:**\n",
    "- Analyzing news topics over years\n",
    "- Tracking research trends in academic papers\n",
    "- Understanding how social media discussions evolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c455df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_topic_evolution(base_documents):\n",
    "    \"\"\"\n",
    "    Simulate how topics might evolve over time.\n",
    "    \n",
    "    Your task: Implement topic evolution analysis\n",
    "    \n",
    "    Steps:\n",
    "    1. Create time-based document collections (provided below)\n",
    "    2. Train separate LDA models for each period\n",
    "    3. Extract topics for each period\n",
    "    4. Track word trends across periods\n",
    "    5. Create visualizations\n",
    "    \n",
    "    Hints:\n",
    "    - Use fewer topics (2-3) for smaller document sets\n",
    "    - Parse topic words from model.print_topics() output\n",
    "    - Use matplotlib to plot word frequency trends\n",
    "    \"\"\"\n",
    "    \n",
    "    # Time-based document collections (already provided)\n",
    "    time_periods = {\n",
    "        'Period 1 (Sports & Food)': [\n",
    "            \"Fu√üball ist sehr beliebt in Deutschland. Viele Menschen spielen gerne Fu√üball.\",\n",
    "            \"Die deutsche Fu√üball-Nationalmannschaft hat schon oft gewonnen.\",\n",
    "            \"Basketball und Tennis sind auch beliebte Sportarten.\",\n",
    "            \"Schnitzel, Bratwurst und Sauerkraut sind typisch deutsche Speisen.\",\n",
    "            \"Viele Menschen kochen gerne zu Hause und probieren neue Rezepte aus.\"\n",
    "        ],\n",
    "        'Period 2 (Technology & Travel)': [\n",
    "            \"Computer und Smartphones sind heute sehr wichtig f√ºr die Arbeit.\",\n",
    "            \"K√ºnstliche Intelligenz und maschinelles Lernen entwickeln sich schnell.\",\n",
    "            \"Viele Unternehmen investieren in neue Technologien und Digitalisierung.\",\n",
    "            \"Reisen macht Spa√ü und man lernt neue Kulturen kennen.\",\n",
    "            \"Urlaub am Meer oder in den Bergen ist sehr entspannend.\"\n",
    "        ],\n",
    "        'Period 3 (Environment & Culture)': [\n",
    "            \"Elektroautos werden immer beliebter und umweltfreundlicher.\",\n",
    "            \"Natur und Umwelt sind wichtig f√ºr unser Leben.\",\n",
    "            \"Garten und Pflanzen pflegen ist ein beliebtes Hobby.\",\n",
    "            \"B√ºcher lesen ist ein sch√∂nes Hobby und sehr entspannend.\",\n",
    "            \"Musik h√∂ren und Konzerte besuchen macht vielen Menschen Freude.\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"Topic Evolution Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    period_models = {}\n",
    "    period_topics = {}\n",
    "    \n",
    "    # TODO: Implement evolution analysis\n",
    "    # 1. Train models for each time period\n",
    "    # 2. Extract topics and words\n",
    "    # 3. Store results\n",
    "    \n",
    "    return period_models, period_topics\n",
    "\n",
    "def analyze_topic_trends(period_topics):\n",
    "    \"\"\"\n",
    "    Analyze trends in topic words across periods.\n",
    "    \n",
    "    Your task: Track word trends and create visualizations\n",
    "    \n",
    "    Steps:\n",
    "    1. Collect all words across all periods\n",
    "    2. Count word frequency in each period\n",
    "    3. Identify increasing/decreasing trends\n",
    "    4. Create trend visualization\n",
    "    \n",
    "    Hints:\n",
    "    - Use set() to collect unique words\n",
    "    - Track word counts across periods\n",
    "    - Compare first and last period to identify trends\n",
    "    - Use different colors for increasing/decreasing trends\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Topic Trend Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # TODO: Implement trend analysis\n",
    "    # Extract words, track frequencies, identify trends\n",
    "    \n",
    "    pass\n",
    "\n",
    "# TODO: Test your evolution analysis\n",
    "# evolution_results = simulate_topic_evolution(extended_documents)\n",
    "# if evolution_results:\n",
    "#     period_models, period_topics = evolution_results\n",
    "#     analyze_topic_trends(period_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b794913",
   "metadata": {},
   "source": [
    "## Exercise 6: Interactive Topic Explorer (Advanced)\n",
    "\n",
    "**Goal:** Create an interactive tool for exploring trained topic models.\n",
    "\n",
    "**Your Tasks:**\n",
    "1. Build a TopicExplorer class that wraps LDA models\n",
    "2. Implement methods for topic exploration and document similarity\n",
    "3. Create an interactive interface for model analysis\n",
    "\n",
    "**Advanced Features:**\n",
    "- Explore individual topics in detail\n",
    "- Find documents similar to a query\n",
    "- Get topic summaries\n",
    "- Calculate document similarities using topic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb58137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopicExplorer:\n",
    "    \"\"\"\n",
    "    Interactive topic exploration tool.\n",
    "    \n",
    "    Your task: Implement the missing methods\n",
    "    \n",
    "    The explorer should allow users to:\n",
    "    1. Explore individual topics (words and related documents)\n",
    "    2. Find documents similar to a query text\n",
    "    3. Get overview summaries of all topics\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, lda_model, corpus, documents, dictionary):\n",
    "        self.lda_model = lda_model\n",
    "        self.corpus = corpus\n",
    "        self.documents = documents\n",
    "        self.dictionary = dictionary\n",
    "        self.doc_topics = None\n",
    "        \n",
    "        if lda_model and corpus:\n",
    "            self._analyze_documents()\n",
    "    \n",
    "    def _analyze_documents(self):\n",
    "        \"\"\"Analyze document-topic relationships for the explorer.\"\"\"\n",
    "        # TODO: Implement document analysis\n",
    "        # Similar to Exercise 3, but store for interactive use\n",
    "        pass\n",
    "    \n",
    "    def explore_topic(self, topic_id, n_words=8, n_docs=5):\n",
    "        \"\"\"\n",
    "        Explore a specific topic in detail.\n",
    "        \n",
    "        Your task: Show topic words and related documents\n",
    "        \n",
    "        Steps:\n",
    "        1. Validate topic_id\n",
    "        2. Get top words for the topic\n",
    "        3. Find documents most related to this topic\n",
    "        4. Display results\n",
    "        \n",
    "        Hints:\n",
    "        - Use lda_model.show_topic() for Gensim models\n",
    "        - Sort documents by topic probability\n",
    "        - Truncate long document text for display\n",
    "        \"\"\"\n",
    "        # TODO: Implement topic exploration\n",
    "        pass\n",
    "    \n",
    "    def find_similar_documents(self, query_text, n_similar=5):\n",
    "        \"\"\"\n",
    "        Find documents similar to a query text.\n",
    "        \n",
    "        Your task: Implement similarity search\n",
    "        \n",
    "        Steps:\n",
    "        1. Preprocess query text\n",
    "        2. Get topic distribution for query\n",
    "        3. Calculate similarity with all documents\n",
    "        4. Return most similar documents\n",
    "        \n",
    "        Hints:\n",
    "        - Use cosine similarity between topic vectors\n",
    "        - You may need scipy.spatial.distance.cosine\n",
    "        - Handle cases where scipy is not available\n",
    "        \"\"\"\n",
    "        # TODO: Implement similarity search\n",
    "        pass\n",
    "    \n",
    "    def get_topic_summary(self):\n",
    "        \"\"\"Get a summary of all topics.\"\"\"\n",
    "        # TODO: Implement topic summary\n",
    "        # Show topic words and document counts\n",
    "        pass\n",
    "\n",
    "# TODO: Test your TopicExplorer (after implementing previous exercises)\n",
    "# if lda_model and hasattr(lda_model, 'get_document_topics') and corpus:\n",
    "#     explorer = TopicExplorer(lda_model, corpus, extended_documents, dictionary)\n",
    "#     explorer.get_topic_summary()\n",
    "#     explorer.explore_topic(0, n_words=6, n_docs=3)\n",
    "#     explorer.find_similar_documents(\"Technologie und Computer\", n_similar=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc68f95f",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "**Congratulations!** üéâ You've completed the topic modeling exercises. Here's what you've learned:\n",
    "\n",
    "### Key Concepts Covered:\n",
    "1. **Simple Topic Discovery**: Using TF-IDF and LDA for basic topic extraction\n",
    "2. **Advanced LDA**: Proper text preprocessing and using Gensim for sophisticated modeling\n",
    "3. **Document-Topic Analysis**: Understanding how documents relate to discovered topics\n",
    "4. **Model Comparison**: Evaluating models with different numbers of topics\n",
    "5. **Topic Evolution**: Analyzing how topics change over time\n",
    "6. **Interactive Exploration**: Building tools for model analysis and document similarity\n",
    "\n",
    "### Skills Developed:\n",
    "- Text preprocessing for German language documents\n",
    "- Feature extraction using TF-IDF\n",
    "- LDA implementation with both scikit-learn and Gensim\n",
    "- Model evaluation using perplexity and coherence\n",
    "- Data visualization for topic analysis\n",
    "- Object-oriented programming for NLP tools\n",
    "\n",
    "### Real-World Applications:\n",
    "- **News Analysis**: Discovering trending topics in news articles\n",
    "- **Social Media**: Understanding discussion themes on platforms\n",
    "- **Academic Research**: Tracking research trends in scientific papers\n",
    "- **Business Intelligence**: Analyzing customer feedback and reviews\n",
    "- **Content Recommendation**: Suggesting similar documents or articles\n",
    "\n",
    "### Further Learning:\n",
    "- Try different preprocessing techniques (lemmatization, n-grams)\n",
    "- Experiment with other topic modeling algorithms (NMF, LSA)\n",
    "- Explore dynamic topic modeling for temporal analysis\n",
    "- Learn about topic model evaluation metrics\n",
    "- Practice with larger, real-world datasets\n",
    "\n",
    "### Troubleshooting Tips:\n",
    "- If you encounter library compatibility issues, try: `pip install gensim==4.1.2`\n",
    "- For large datasets, consider using online learning algorithms\n",
    "- Experiment with different numbers of topics - there's no \"perfect\" number\n",
    "- Topic modeling is iterative - try different preprocessing and parameters\n",
    "\n",
    "**Great job on completing these challenging exercises!** üöÄ\n",
    "\n",
    "The complete solutions are available in the `solutions/` folder for reference."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
